params {
  outdir = 'results'
  help = false

  // Defaults only, expecting to be overwritten
  max_memory = 128.GB
  max_cpus = 16
  max_time = 240.h

  ref = 'https://github.com/czbiohub/test-datasets/raw/msspe/reference/MN908947.3.fa'
  ref_host = 'http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz'
  ref_gb = "https://github.com/czbiohub/test-datasets/raw/olgabot/msspe--add-human-and-kraken/reference/MN908947.3.gb"
  primers = 'https://github.com/czbiohub/test-datasets/raw/msspe/reference/SARS-COV-2_spikePrimers.bed'

  single_end = false
  skip_trim_adapters = false
  skip_filter_ref = false
  readPaths = false

  // TODO update path to non-olga branch
  qpcr_primers = "https://github.com/czbiohub/test-datasets/raw/olgabot/msspe--add-human-and-kraken/testdata/qpcr_primers.bed"
  ercc_fasta = "https://github.com/czbiohub/test-datasets/raw/olgabot/msspe--add-human-and-kraken/testdata/ercc_sequences.fasta"

  samQualThreshold = 20

  minDepth = 10

  clades = "https://github.com/czbiohub/test-datasets/raw/olgabot/msspe--add-human-and-kraken/testdata/data/clades.tsv"

  // assumes about 20 mutations between 2 random samples
  // (this is an overestimate to increase sensitivity)
  bcftoolsCallTheta = 0.0006

  exclude_samples = ""

// iVar defaults
  ivarQualThreshold = 20
  ivarFreqThreshold = 0.9
  mpileupDepth = 10000

// QUAST
  maxNs = 100
  minLength = 25000
  no_reads_quast = false

  //kraken2_db = "https://storage.googleapis.com/sars-cov-2/kraken2_h%2Bv_20200319.tar.gz"

// Analysis params
  sample_vcfs = false

// Nextstrain data
  nextstrain_sequences = ""
  nextstrain_ncov = "https://raw.githubusercontent.com/nextstrain/ncov/master/"
  subsample = 200
  sequences_per_group_1 = 500
  sequences_per_group_2 = 20
  sample_metadata = false
  sample_sequences = false
  group_by = 'division year month'
  existing_alignment = false

// whether to create a joint VCF
  joint_variant_calling = false

// Output documentation
  multiqc_config = "$baseDir/assets/multiqc_config.yaml"

}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
	return params.max_memory as nextflow.util.MemoryUnit
      else
	return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
	return params.max_time as nextflow.util.Duration
      else
	return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}

process {

    cpus = { check_max( 2 * task.attempt, 'cpus') }
    memory = { check_max( 4.GB * task.attempt, 'memory') }
    time = { check_max( 1.h * task.attempt, 'time') }

    errorStrategy = { task.attempt < 4 ? 'retry' : 'finish' }
    maxRetries = 3
    maxErrors = '-1'

    container = 'czbiohub/sc2-msspe'

    withLabel:'process_pileup' {
        memory = { check_max(16.GB * task.attempt, 'memory') }
        time = { check_max (8.h * task.attempt, 'time')}
    }
    withLabel:'process_large' {
        cpus = { check_max(8 * task.attempt, 'cpus') }
        memory = { check_max(16.GB * task.attempt, 'memory') }
        time = { check_max (8.h * task.attempt, 'time')}
    }
    withLabel:'process_medium' {
        cpus = { check_max(4 * task.attempt, 'cpus') }
        memory = { check_max(8.GB * task.attempt, 'memory') }
        time = { check_max (2.h * task.attempt, 'time')}
    }
    withLabel:'process_small' {
        cpus = { check_max(2 * task.attempt, 'cpus') }
        memory = { check_max(4.GB * task.attempt, 'memory') }
        time = { check_max (1.h * task.attempt, 'time')}
    }
    withLabel:'process_tiny' {
        cpus = { check_max(1 * task.attempt, 'cpus') }
        memory = { check_max(2.GB * task.attempt, 'memory') }
        time = { check_max (1.h * task.attempt, 'time')}
    }

}

// Profiles
profiles {
  conda { process.conda = "$baseDir/environment.yaml" }
  //debug { process.beforeScript = 'echo $HOSTNAME' }
  docker { docker.enabled = true }
  //singularity { singularity.enabled = true }
  awsbatch { includeConfig 'conf/awsbatch.config' }
  // settings for prefiltered fastas of reads
  fasta_reads { includeConfig 'conf/fasta_reads.config' }
  // test datasets
  benchmark { includeConfig 'conf/benchmark.config' }
  test { includeConfig 'conf/test.config' }
  test_nextstrain { includeConfig 'conf/test_nextstrain.config' }
  test_fasta_reads { includeConfig 'conf/test_fasta_reads.config' }
  test_awsbatch { includeConfig 'conf/test_awsbatch.config' }
}

process.shell = ['/bin/bash', '-euo', 'pipefail']

manifest {
  name = 'czbiohub/sc2-msspe2-bioinfo'
  author = 'Jack Kamm and Samantha Hao'
  homePage = 'https://github.com/czbiohub/sc2-msspe2-bioinfo'
  description = 'Generate consensus SARS-CoV-2 genomes from FASTQ files'
  mainScript = 'main.nf'
  nextflowVersion = '>=19.10.0'
  version = '1.0.0dev'
}
